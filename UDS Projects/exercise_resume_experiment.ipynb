{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resume Experiment Analysis\n",
    "\n",
    "Luopeiwen Yi\n",
    "\n",
    "How much harder is it to get a job in the United States if you are Black than if you are White? Or, expressed differently, what is the *effect* of race on the difficulty of getting a job in the US?\n",
    "\n",
    "In this exercise, we will be analyzing data from a real world experiment designed to help answer this question. Namely, we will be analyzing data from a randomized experiment in which 4,870 ficticious resumes were sent out to employers in response to job adverts in Boston and Chicago in 2001. The resumes differ in various attributes including the names of the applicants, and different resumes were randomly allocated to job openings. \n",
    "\n",
    "The \"experiment\" part of the experiment is that resumes were randomly assigned Black- or White-sounding names, and then watched to see whether employers called the \"applicants\" with Black-sounding names at the same rate as the applicants with the White-sounding names.\n",
    "\n",
    "(Which names constituted \"Black-sounding names\" and \"White-sounding names\" was determined by analyzing names on Massachusetts birth certificates to determine which names were most associated with Black and White children, and then surveys were used to validate that the names were perceived as being associated with individuals of one racial category or the other. Also, please note I subscribe to the logic of [Kwame Anthony Appiah](https://www.theatlantic.com/ideas/archive/2020/06/time-to-capitalize-blackand-white/613159/) and chose to capitalize both the B in Black and the W in White). \n",
    "\n",
    "You can get access to original article [here](https://www.aeaweb.org/articles?id=10.1257/0002828042002561). \n",
    "\n",
    "**Note to Duke students:** if you are on the Duke campus network, you'll be able to access almost any academic journal articles directly; if you are off campus and want access, you can just go to the [Duke Library](https://library.duke.edu/) website and search for the article title. Once you find it, you'll be asked to log in, after which you'll have full access to the article. You will also find this pattern holds true at nearly any major University in the US.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from scipy.stats import ttest_ind\n",
    "import warnings\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option(\"mode.copy_on_write\", True)\n",
    "\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Gradescope Autograding\n",
    "\n",
    "Please follow [all standard guidance](https://www.practicaldatascience.org/html/autograder_guidelines.html) for submitting this assignment to the Gradescope autograder, including storing your solutions in a dictionary called `results` and ensuring your notebook runs from the start to completion without any errors.\n",
    "\n",
    "For this assignment, please name your file `exercise_resume_experiment.ipynb` before uploading.\n",
    "\n",
    "You can check that you have answers for all questions in your `results` dictionary with this code:\n",
    "\n",
    "```python\n",
    "assert set(results.keys()) == {\n",
    "    \"ex2_pvalue_computerskills\",\n",
    "    \"ex2_pvalue_female\",\n",
    "    \"ex2_pvalue_yearsexp\",\n",
    "    \"ex3_pvalue_education\",\n",
    "    \"ex4_validity\",\n",
    "    \"ex5_pvalue\",\n",
    "    \"ex5_white_advantage_percent\",\n",
    "    \"ex5_white_advantage_percentage_points\",\n",
    "    \"ex6_black_pvalue\",\n",
    "    \"ex8_black_college\",\n",
    "    \"ex8_black_nocollege\",\n",
    "    \"ex8_college_heterogeneity\",\n",
    "    \"ex9_gender_and_discrimination\",\n",
    "    \"ex10_experiment_v_us\",\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "### Submission Limits\n",
    "\n",
    "Please remember that you are **only allowed FOUR submissions to the autograder.** Your last submission (if you submit 4 or fewer times), or your third submission (if you submit more than 4 times) will determine your grade Submissions that error out will **not** count against this total.\n",
    "\n",
    "That's one more than usual in case there are issues with exercise clarity."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for Balance\n",
    "\n",
    "The first step in analyzing any experiment is to check whether you have *balance* across your treatment arms—that is to say, do the people who were randomly assigned to the treatment group look like the people who were randomly assigned to the control group. Or in this case, do the resumes that ended up with Black-sounding names look like the resumes with White-sounding names. \n",
    "\n",
    "Checking for balance is critical for two reasons. First, it's always possible that random assignment will create profoundly different groups—the *Large of Large Numbers* is only a \"law\" in the limit. So we want to make sure we have reasonably similar groups from the outset. And second, it's also always possible that the randomization wasn't actually implemented correctly—you would be amazed at the number of ways that \"random assignment\" can go wrong! So if you ever do find you're getting unbalanced data, you should worry not only about whether the groups have baseline differences, but also whether the \"random assignment\" was actually random!\n",
    "\n",
    "### Exercise 1\n",
    "\n",
    "Download the data set from this experiment (`resume_experiment.dta`) from [github](https://github.com/nickeubank/MIDS_Data/tree/master/resume_experiment). To aid the autograder, please load the data directly from a URL.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>education</th>\n",
       "      <th>ofjobs</th>\n",
       "      <th>yearsexp</th>\n",
       "      <th>computerskills</th>\n",
       "      <th>call</th>\n",
       "      <th>female</th>\n",
       "      <th>black</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   education  ofjobs  yearsexp  computerskills  call  female  black\n",
       "0          4       2         6               1   0.0     1.0    0.0\n",
       "1          3       3         6               1   0.0     1.0    0.0\n",
       "2          4       1         6               1   0.0     1.0    1.0\n",
       "3          3       4         6               1   0.0     1.0    1.0\n",
       "4          3       3        22               1   0.0     1.0    0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume = pd.read_stata(\n",
    "    \"https://github.com/nickeubank/MIDS_Data/raw/master/resume_experiment/resume_experiment.dta\"\n",
    ")\n",
    "resume.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Exercise 2\n",
    "\n",
    "- `black` is the treatment variable in the data set (whether the resume has a \"Black-sounding\" name).\n",
    "- `call` is the dependent variable of interest (did the employer call the fictitious applicant for an interview)\n",
    "\n",
    "In addition, the data include a number of variables to describe the other features in each fictitious resume, including applicants education level (`education`), years of experience (`yearsexp`), gender (`female`), computer skills (`computerskills`), and number of previous jobs (`ofjobs`). Each resume has a random selection of these attributes, so on average the Black-named fictitious applicant resumes have the same qualifications as the White-named applicant resumes. \n",
    "\n",
    "Check for balance in terms of the average values of applicant gender (`female`), computer skills (`computerskills`), and years of experience (`yearsexp`) across the two arms of the experiment (i.e. by `black`). Calculate both the differences in means across treatment arms *and* test for statistical significance of these differences. Does gender, computer skills, and yearsexp look balanced across race groups in terms of both statistical significance and magnitude of difference?\n",
    "\n",
    "Store the p-values associated with your t-test of these variables in `ex2_pvalue_female`, `ex2_pvalue_computerskills`, and `ex2_pvalue_yearsexp`. **Round your values to 2 decimal places.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The difference in means for gender between the Black group and White group is around: 0.01.\n",
      "The difference in means for computer skills between the Black group and White group are around :0.02.\n",
      "The difference in means for years of experience between the Black group and White group are around :-0.03.\n"
     ]
    }
   ],
   "source": [
    "# Separating the groups to be\n",
    "group_black = resume[resume[\"black\"] == 1]\n",
    "group_white = resume[resume[\"black\"] == 0]\n",
    "\n",
    "# Computing differences in means for gender, computer skills, years of experience in the two groups\n",
    "mean_diff_female = group_black[\"female\"].mean() - group_white[\"female\"].mean()\n",
    "mean_diff_computerskills = (\n",
    "    group_black[\"computerskills\"].mean() - group_white[\"computerskills\"].mean()\n",
    ")\n",
    "mean_diff_yearsexp = group_black[\"yearsexp\"].mean() - group_white[\"yearsexp\"].mean()\n",
    "\n",
    "print(\n",
    "    f\"The difference in means for gender between the Black group and White group is around: {mean_diff_female:.2f}.\"\n",
    ")\n",
    "print(\n",
    "    f\"The difference in means for computer skills between the Black group and White group are around :{mean_diff_computerskills:.2f}.\"\n",
    ")\n",
    "print(\n",
    "    f\"The difference in means for years of experience between the Black group and White group are around :{mean_diff_yearsexp:.2f}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-test for the difference in means for gender between the Black group and White group: \n",
      "TtestResult(statistic=0.8841321196036144, pvalue=0.37666855949097355, df=4868.0)\n",
      "t-test for the difference in means for computer skills between the Black group and White group: \n",
      "TtestResult(statistic=2.1664271042751966, pvalue=0.03032693395539194, df=4868.0)\n",
      "t-test for the difference in means for years of experience between the Black group and White group: \n",
      "TtestResult(statistic=-0.18461970685747395, pvalue=0.8535350182481283, df=4868.0)\n"
     ]
    }
   ],
   "source": [
    "# Statistical significance (t-tests)\n",
    "t_test_female = ttest_ind(group_black[\"female\"], group_white[\"female\"])\n",
    "t_test_computerskills = ttest_ind(\n",
    "    group_black[\"computerskills\"], group_white[\"computerskills\"]\n",
    ")\n",
    "t_test_yearsexp = ttest_ind(group_black[\"yearsexp\"], group_white[\"yearsexp\"])\n",
    "\n",
    "print(\n",
    "    \"t-test for the difference in means for gender between the Black group and White group: \"\n",
    ")\n",
    "print(t_test_female)\n",
    "print(\n",
    "    \"t-test for the difference in means for computer skills between the Black group and White group: \"\n",
    ")\n",
    "print(t_test_computerskills)\n",
    "print(\n",
    "    \"t-test for the difference in means for years of experience between the Black group and White group: \"\n",
    ")\n",
    "print(t_test_yearsexp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value of t-test for the difference in means for gender between the Black group and White group: 0.38\n",
      "p-value of t-test for the difference in means for computers skills between the Black group and White group: 0.03\n",
      "p-value of t-test for the difference in means for years of experience between the Black group and White group: 0.85\n"
     ]
    }
   ],
   "source": [
    "# Storing p-values with 2 decimal places\n",
    "results[\"ex2_pvalue_female\"] = round(t_test_female.pvalue, 2)\n",
    "results[\"ex2_pvalue_computerskills\"] = round(t_test_computerskills.pvalue, 2)\n",
    "results[\"ex2_pvalue_yearsexp\"] = round(t_test_yearsexp.pvalue, 2)\n",
    "\n",
    "print(\n",
    "    f\"p-value of t-test for the difference in means for gender between the Black group and White group: {round(t_test_female.pvalue, 2)}\"\n",
    ")\n",
    "print(\n",
    "    f\"p-value of t-test for the difference in means for computers skills between the Black group and White group: {round(t_test_computerskills.pvalue, 2)}\"\n",
    ")\n",
    "print(\n",
    "    f\"p-value of t-test for the difference in means for years of experience between the Black group and White group: {round(t_test_yearsexp.pvalue, 2)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - **Magnitude of Difference**: All three variables (gender, computer skills, and years of experience) show very small differences in means between the Black and White groups, suggesting the groups can be considered balanced on these characteristics.\n",
    "> - **Statistical Significance**: Only the computer skills show a statistically significant difference between the Black and White groups (p-value<0.05), suggesting a lack of balance in this characteristic between the two groups. In contrast, there's no statistically significant difference for gender or years of experience across the two race groups (p-value>0.05), suggesting balance in these characteristics across the two groups. \n",
    "> - Overall, while gender and years of experience appear balanced across race groups both in terms of statistical significance and magnitude, computer skills show a statistically significant difference despite the small magnitude of the difference."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Do a similar tabulation for education (`education`). Education is a categorical variable coded as follows:\n",
    "\n",
    "- 0: Education not reported\n",
    "- 1: High school dropout\n",
    "- 2: High school graduate\n",
    "- 3: Some college\n",
    "- 4: College graduate or higher\n",
    "\n",
    "Because these are categorical, you shouldn't just calculate and compare means—you should compare share or count of observations with each value (e.g., a chi-squared contingency table). You may also find the `pd.crosstab` function useful.\n",
    "\n",
    "Does education look balanced across racial groups?\n",
    "\n",
    "Store the p-value from your chi squared test in results under the key `ex3_pvalue_education`. **Please round to 2 decimal places.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The contingency table is\n",
      "black       0.0   1.0\n",
      "education            \n",
      "0            18    28\n",
      "1            18    22\n",
      "2           142   132\n",
      "3           513   493\n",
      "4          1744  1760\n"
     ]
    }
   ],
   "source": [
    "# Creating a contingency table for education across racial groups\n",
    "contingency_table_education = pd.crosstab(resume[\"education\"], resume[\"black\"])\n",
    "\n",
    "print(f\"The contingency table is\")\n",
    "print(contingency_table_education)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The p-value from my chi square test for the difference in means for education between the Black group and White group is around:  0.49\n"
     ]
    }
   ],
   "source": [
    "# Performing chi-squared test\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table_education)\n",
    "\n",
    "print(\n",
    "    \"The p-value from my chi square test for the difference in means for education between the Black group and White group is around: \",\n",
    "    round(p, 2),\n",
    ")\n",
    "# Storing p-value, rounded to 2 decimal places\n",
    "results[\"ex3_pvalue_education\"] = round(p, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> There is no statistically significant difference in the distribution of education levels between the two racial groups (p value>0.05), indicating the education appears to be balanced across racial groups."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "What do you make of the overall results on resume characteristics? Why do we care about whether these variables look similar across the race groups? And if they didn't look similar, would that be a threat to internal or external validity? \n",
    "\n",
    "Answer in markdown, then also store your answer to the question of whether imbalances are a threat to internal or external validity in `\"ex4_validity\"` as the string `\"internal\"` or `\"external\"`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - The overall results on resume characteristics suggest that, except for computer skills, the variables of gender, years of experience, and education level appear to be balanced across the race groups. This balance is crucial in ensuring the fairness and accuracy of the experimental design, which in this context aims to assess the impact of race (as indicated by \"Black-sounding\" vs. \"White-sounding\" names) on the likelihood of being called for an interview.\n",
    "> - The similarity of these variables across race groups is essential. It helps to control for confounding variables that could otherwise skew the results. For instance, if one racial group had significantly higher computer skill levels, any difference in call-back rates could be attributed to this factor rather than the race signal sent by the name on the resume.\n",
    "> - If these variables does not look similar across the race groups, it would primarily pose a threat to the internal validity of the study. Differences in variables such as gender, education, experience, or computer skills across race groups could confound the results, making it difficult to attribute any difference in call-back rates to the race signal alone. This could lead to incorrect conclusions about the impact of racial bias in hiring practices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"ex4_validity\"] = \"internal\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating Effect of Race"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "The variable of interest in the data set is the variable `call`, which indicates a call back for an interview. Perform a two-sample t-test comparing applicants with black sounding names and white sounding names.\n",
    "\n",
    "Interpret your results—in both percentage *and* in percentage points, what is the effect of having a Black-sounding name (as opposed to a White-sounding name) on your resume?\n",
    "\n",
    "Store how much more likely a White applicant is to receive a call back than a Black respondent in percentage and percentage points in `\"ex5_white_advantage_percent\"`and `\"ex5_white_advantage_percentage_points\"`. Please scale percentages so 1 is 1% and percentage points so a value of `1` corresponds to 1 percentage point. **Please round these answers to 2 decimal places.**\n",
    "\n",
    "Store the p-value of the difference in `\"ex5_pvalue\"` **Please round your p-value to 5 decimal places.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-sample t-test comparing the callback for an interview for applicants with black sounding names and white sounding names:\n",
      "TtestResult(statistic=-4.114705356750735, pvalue=3.940800981423711e-05, df=4868.0)\n"
     ]
    }
   ],
   "source": [
    "# Splitting data based on 'black' variable\n",
    "group_black_callback = resume[resume[\"black\"] == 1][\"call\"]\n",
    "group_white_callback = resume[resume[\"black\"] == 0][\"call\"]\n",
    "\n",
    "t_stat_race = ttest_ind(group_black_callback, group_white_callback)\n",
    "\n",
    "print(\n",
    "    \"Two-sample t-test comparing the callback for an interview for applicants with black sounding names and white sounding names:\"\n",
    ")\n",
    "print(t_stat_race)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value of t-test for the difference in means for callback between applicants with black sounding names and white sounding names is around :  4e-05\n"
     ]
    }
   ],
   "source": [
    "p_value = t_stat_race[1]\n",
    "\n",
    "print(\n",
    "    \"p-value of t-test for the difference in means for callback between applicants with black sounding names and white sounding names is around : \",\n",
    "    round(p_value, 5),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An applicant with white sounding name is 49.68% more likely to receive a call back than an applicant with black sounding name.\n",
      "An applicant with white sounding name is 3.2 percentage points more likely to receive a call back than an applicant with black sounding name.\n"
     ]
    }
   ],
   "source": [
    "# Calculating much more likely a White applicant is to receive a call back than a Black respondent.\n",
    "white_advantage_percent = (\n",
    "    (group_white_callback.mean() - group_black_callback.mean())\n",
    "    / group_black_callback.mean()\n",
    "    * 100\n",
    ")  # Conversion to percentage\n",
    "white_advantage_percentage_points = (\n",
    "    group_white_callback.mean() - group_black_callback.mean()\n",
    ") * 100  # Conversion to percentage points\n",
    "\n",
    "print(\n",
    "    f\"An applicant with white sounding name is {round(white_advantage_percent, 2)}% more likely to receive a call back than an applicant with black sounding name.\"\n",
    ")\n",
    "print(\n",
    "    f\"An applicant with white sounding name is {round(white_advantage_percentage_points, 2)} percentage points more likely to receive a call back than an applicant with black sounding name.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the rounded values\n",
    "results[\"ex5_white_advantage_percent\"] = round(white_advantage_percent, 2)\n",
    "results[\"ex5_white_advantage_percentage_points\"] = round(\n",
    "    white_advantage_percentage_points, 2\n",
    ")\n",
    "results[\"ex5_pvalue\"] = round(p_value, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> There is a statistically significant difference in the callback rates for interviews between applicants with Black-sounding names and those with White-sounding names (p value<0.05). A White applicant is 49.68% more likely to receive a call back than a Black respondent. In absolute terms, the callback rate for White applicants is 3.2 percentage points higher than for Black applicants. Overall, the effect of having a Black-sounding name on a resume, as indicated by this analysis, suggests a statistically significant negative impact (3.2 percentage points lower) on the likelihood of being called back for an interview compared to having a White-sounding name on a resume. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "\n",
    "Now, use a linear probability model (a linear regression with a 0/1 dependent variable!) to estimate the differential likelihood of being called back by applicant race (i.e. the racial discrimination by employers). Please use [statsmodels](https://www.statsmodels.org/stable/index.html).\n",
    "\n",
    "Since we have a limited dependent variable, be sure to use [heteroskedastic robust standard errors.](https://www.statsmodels.org/stable/generated/statsmodels.regression.linear_model.OLSResults.get_robustcov_results.html) Personally, I prefer the `HC3` implementation, as it tends to do better with smaller samples than other implementations.\n",
    "\n",
    "Interpret these results—what is the *effect* of having a Black-sounding name (as opposed to a White-sounding name) on your resume in terms of the likelihood you'll be called back? \n",
    "\n",
    "How does this compare to the estimate you got above in exercise 5?\n",
    "\n",
    "Store the p-value associated with `black` in `\"ex6_black_pvalue\"`. **Please round your pvalue to 5 decimal places.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>call</td>       <th>  R-squared:         </th> <td>   0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   16.92</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 04 Mar 2024</td> <th>  Prob (F-statistic):</th> <td>3.96e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:32:34</td>     <th>  Log-Likelihood:    </th> <td> -562.24</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4870</td>      <th>  AIC:               </th> <td>   1128.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4868</td>      <th>  BIC:               </th> <td>   1141.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>         <td>HC3</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    0.0965</td> <td>    0.006</td> <td>   16.121</td> <td> 0.000</td> <td>    0.085</td> <td>    0.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>black</th>     <td>   -0.0320</td> <td>    0.008</td> <td>   -4.114</td> <td> 0.000</td> <td>   -0.047</td> <td>   -0.017</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>2969.205</td> <th>  Durbin-Watson:     </th> <td>   1.440</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>18927.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 3.068</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>10.458</td>  <th>  Cond. No.          </th> <td>    2.62</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors are heteroscedasticity robust (HC3)"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &       call       & \\textbf{  R-squared:         } &     0.003   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.003   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     16.92   \\\\\n",
       "\\textbf{Date:}             & Mon, 04 Mar 2024 & \\textbf{  Prob (F-statistic):} &  3.96e-05   \\\\\n",
       "\\textbf{Time:}             &     21:32:34     & \\textbf{  Log-Likelihood:    } &   -562.24   \\\\\n",
       "\\textbf{No. Observations:} &        4870      & \\textbf{  AIC:               } &     1128.   \\\\\n",
       "\\textbf{Df Residuals:}     &        4868      & \\textbf{  BIC:               } &     1141.   \\\\\n",
       "\\textbf{Df Model:}         &           1      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &       HC3        & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &       0.0965  &        0.006     &    16.121  &         0.000        &        0.085    &        0.108     \\\\\n",
       "\\textbf{black}     &      -0.0320  &        0.008     &    -4.114  &         0.000        &       -0.047    &       -0.017     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 2969.205 & \\textbf{  Durbin-Watson:     } &     1.440  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000  & \\textbf{  Jarque-Bera (JB):  } & 18927.068  \\\\\n",
       "\\textbf{Skew:}          &   3.068  & \\textbf{  Prob(JB):          } &      0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  10.458  & \\textbf{  Cond. No.          } &      2.62  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors are heteroscedasticity robust (HC3)"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   call   R-squared:                       0.003\n",
       "Model:                            OLS   Adj. R-squared:                  0.003\n",
       "Method:                 Least Squares   F-statistic:                     16.92\n",
       "Date:                Mon, 04 Mar 2024   Prob (F-statistic):           3.96e-05\n",
       "Time:                        21:32:34   Log-Likelihood:                -562.24\n",
       "No. Observations:                4870   AIC:                             1128.\n",
       "Df Residuals:                    4868   BIC:                             1141.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:                  HC3                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.0965      0.006     16.121      0.000       0.085       0.108\n",
       "black         -0.0320      0.008     -4.114      0.000      -0.047      -0.017\n",
       "==============================================================================\n",
       "Omnibus:                     2969.205   Durbin-Watson:                   1.440\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            18927.068\n",
       "Skew:                           3.068   Prob(JB):                         0.00\n",
       "Kurtosis:                      10.458   Cond. No.                         2.62\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors are heteroscedasticity robust (HC3)\n",
       "\"\"\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## fit the model\n",
    "model_callback_race = smf.ols(formula=\"call ~ black\", data=resume).fit()\n",
    "\n",
    "## use robust standard errors\n",
    "robust_results = model_callback_race.get_robustcov_results(cov_type=\"HC3\")\n",
    "\n",
    "## summary output\n",
    "robust_results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient for the difference in likelihood of being called back by having black sounding name comparing to having white sounding name: -0.03203\n",
      "P-value for the difference in likelihood of being called back by having black sounding name comparing to having white sounding name: 4e-05\n"
     ]
    }
   ],
   "source": [
    "# Printing out the coefficient and p-value for 'black'\n",
    "black_coefficient = robust_results.params[1]\n",
    "black_pvalue = robust_results.pvalues[1]\n",
    "\n",
    "print(\n",
    "    f\"Coefficient for the difference in likelihood of being called back by having black sounding name comparing to having white sounding name: {round(black_coefficient, 5)}\"\n",
    ")\n",
    "print(\n",
    "    f\"P-value for the difference in likelihood of being called back by having black sounding name comparing to having white sounding name: {round(black_pvalue, 5)}\"\n",
    ")\n",
    "\n",
    "## store the result\n",
    "results[\"ex6_black_pvalue\"] = round(black_pvalue, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - The coefficient -0.03203 indicates that, applicant with a Black-sounding name on the resume is 3.203 percentage points less likely to receive a callback compared to applicant with a White-sounding name. The p-value 4e-05 indicates that there is a statistically significant difference in callback rates based on the name's racial association. Overall, the effect of having a Black-sounding name on a resume, as indicated by this analysis, suggests a statistically significant negative impact on the likelihood of being called back for an interview. \n",
    "> - The result I got from the linear probability model is consistent with the estimate I got above in exercise 5 (around 3.2 percentage points difference between the racial group callback rates). Both analyses confirm the statistical significance of the difference in callback rates for interviews between applicants with Black-sounding names and those with White-sounding names (p value<0.05)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7\n",
    "\n",
    "Even when doing a randomized experiment, adding control variables to your regression *can* improve the statistical efficiency of your estimates of the treatment effect (the upside is the potential to explain residual variation; the downside is more parameters to be estimated). Adding controls can be particularly useful when randomization left some imbalances in covariates (which you may have seen above). \n",
    "\n",
    "Now let's see if we can improve our estimates by adding in other variables as controls. Add in `education`, `yearsexp`, `female`, and `computerskills`—be sure to treat education as a categorical variable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>call</td>       <th>  R-squared:         </th> <td>   0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   4.350</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 04 Mar 2024</td> <th>  Prob (F-statistic):</th> <td>3.04e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:32:34</td>     <th>  Log-Likelihood:    </th> <td> -551.02</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4870</td>      <th>  AIC:               </th> <td>   1120.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4861</td>      <th>  BIC:               </th> <td>   1178.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     8</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>         <td>HC3</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>         <td>    0.0821</td> <td>    0.040</td> <td>    2.053</td> <td> 0.040</td> <td>    0.004</td> <td>    0.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(education)[T.1]</th> <td>   -0.0017</td> <td>    0.057</td> <td>   -0.030</td> <td> 0.976</td> <td>   -0.113</td> <td>    0.110</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(education)[T.2]</th> <td>-8.953e-05</td> <td>    0.042</td> <td>   -0.002</td> <td> 0.998</td> <td>   -0.082</td> <td>    0.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(education)[T.3]</th> <td>   -0.0025</td> <td>    0.039</td> <td>   -0.065</td> <td> 0.948</td> <td>   -0.079</td> <td>    0.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(education)[T.4]</th> <td>   -0.0047</td> <td>    0.038</td> <td>   -0.124</td> <td> 0.901</td> <td>   -0.080</td> <td>    0.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>black</th>             <td>   -0.0316</td> <td>    0.008</td> <td>   -4.076</td> <td> 0.000</td> <td>   -0.047</td> <td>   -0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yearsexp</th>          <td>    0.0032</td> <td>    0.001</td> <td>    3.665</td> <td> 0.000</td> <td>    0.001</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>female</th>            <td>    0.0112</td> <td>    0.010</td> <td>    1.165</td> <td> 0.244</td> <td>   -0.008</td> <td>    0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>computerskills</th>    <td>   -0.0186</td> <td>    0.011</td> <td>   -1.616</td> <td> 0.106</td> <td>   -0.041</td> <td>    0.004</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>2950.646</td> <th>  Durbin-Watson:     </th> <td>   1.448</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>18631.250</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 3.047</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>10.395</td>  <th>  Cond. No.          </th> <td>    225.</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors are heteroscedasticity robust (HC3)"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &       call       & \\textbf{  R-squared:         } &     0.008   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.006   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     4.350   \\\\\n",
       "\\textbf{Date:}             & Mon, 04 Mar 2024 & \\textbf{  Prob (F-statistic):} &  3.04e-05   \\\\\n",
       "\\textbf{Time:}             &     21:32:34     & \\textbf{  Log-Likelihood:    } &   -551.02   \\\\\n",
       "\\textbf{No. Observations:} &        4870      & \\textbf{  AIC:               } &     1120.   \\\\\n",
       "\\textbf{Df Residuals:}     &        4861      & \\textbf{  BIC:               } &     1178.   \\\\\n",
       "\\textbf{Df Model:}         &           8      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &       HC3        & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                           & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}         &       0.0821  &        0.040     &     2.053  &         0.040        &        0.004    &        0.160     \\\\\n",
       "\\textbf{C(education)[T.1]} &      -0.0017  &        0.057     &    -0.030  &         0.976        &       -0.113    &        0.110     \\\\\n",
       "\\textbf{C(education)[T.2]} &   -8.953e-05  &        0.042     &    -0.002  &         0.998        &       -0.082    &        0.082     \\\\\n",
       "\\textbf{C(education)[T.3]} &      -0.0025  &        0.039     &    -0.065  &         0.948        &       -0.079    &        0.074     \\\\\n",
       "\\textbf{C(education)[T.4]} &      -0.0047  &        0.038     &    -0.124  &         0.901        &       -0.080    &        0.070     \\\\\n",
       "\\textbf{black}             &      -0.0316  &        0.008     &    -4.076  &         0.000        &       -0.047    &       -0.016     \\\\\n",
       "\\textbf{yearsexp}          &       0.0032  &        0.001     &     3.665  &         0.000        &        0.001    &        0.005     \\\\\n",
       "\\textbf{female}            &       0.0112  &        0.010     &     1.165  &         0.244        &       -0.008    &        0.030     \\\\\n",
       "\\textbf{computerskills}    &      -0.0186  &        0.011     &    -1.616  &         0.106        &       -0.041    &        0.004     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 2950.646 & \\textbf{  Durbin-Watson:     } &     1.448  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000  & \\textbf{  Jarque-Bera (JB):  } & 18631.250  \\\\\n",
       "\\textbf{Skew:}          &   3.047  & \\textbf{  Prob(JB):          } &      0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  10.395  & \\textbf{  Cond. No.          } &      225.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors are heteroscedasticity robust (HC3)"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   call   R-squared:                       0.008\n",
       "Model:                            OLS   Adj. R-squared:                  0.006\n",
       "Method:                 Least Squares   F-statistic:                     4.350\n",
       "Date:                Mon, 04 Mar 2024   Prob (F-statistic):           3.04e-05\n",
       "Time:                        21:32:34   Log-Likelihood:                -551.02\n",
       "No. Observations:                4870   AIC:                             1120.\n",
       "Df Residuals:                    4861   BIC:                             1178.\n",
       "Df Model:                           8                                         \n",
       "Covariance Type:                  HC3                                         \n",
       "=====================================================================================\n",
       "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------\n",
       "Intercept             0.0821      0.040      2.053      0.040       0.004       0.160\n",
       "C(education)[T.1]    -0.0017      0.057     -0.030      0.976      -0.113       0.110\n",
       "C(education)[T.2] -8.953e-05      0.042     -0.002      0.998      -0.082       0.082\n",
       "C(education)[T.3]    -0.0025      0.039     -0.065      0.948      -0.079       0.074\n",
       "C(education)[T.4]    -0.0047      0.038     -0.124      0.901      -0.080       0.070\n",
       "black                -0.0316      0.008     -4.076      0.000      -0.047      -0.016\n",
       "yearsexp              0.0032      0.001      3.665      0.000       0.001       0.005\n",
       "female                0.0112      0.010      1.165      0.244      -0.008       0.030\n",
       "computerskills       -0.0186      0.011     -1.616      0.106      -0.041       0.004\n",
       "==============================================================================\n",
       "Omnibus:                     2950.646   Durbin-Watson:                   1.448\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            18631.250\n",
       "Skew:                           3.047   Prob(JB):                         0.00\n",
       "Kurtosis:                      10.395   Cond. No.                         225.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors are heteroscedasticity robust (HC3)\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## fit the model\n",
    "model_callback_all = smf.ols(\n",
    "    formula=\"call ~ black + C(education) + yearsexp + female + computerskills\",\n",
    "    data=resume,\n",
    ").fit()\n",
    "\n",
    "## robust standard error\n",
    "robust_new_model = model_callback_all.get_robustcov_results(cov_type=\"HC3\")\n",
    "\n",
    "## summary\n",
    "robust_new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient for the difference in likelihood of being called back by having black sounding name comparing to having white sounding name, controlling for other factors: -0.03161\n",
      "P-value for the difference in likelihood of being called back by having black sounding name comparing to having white sounding name: 5e-05\n"
     ]
    }
   ],
   "source": [
    "# Printing out the coefficient and p-value for 'black'\n",
    "black_coefficient_new = robust_new_model.params[5]\n",
    "black_pvalue_new = robust_new_model.pvalues[5]\n",
    "\n",
    "print(\n",
    "    f\"Coefficient for the difference in likelihood of being called back by having black sounding name comparing to having white sounding name, controlling for other factors: {round(black_coefficient_new, 5)}\"\n",
    ")\n",
    "print(\n",
    "    f\"P-value for the difference in likelihood of being called back by having black sounding name comparing to having white sounding name: {round(black_pvalue_new, 5)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - The coefficient -0.03161 indicates that, applicant with a Black-sounding name on the resume is 3.161 percentage points less likely to receive a callback compared to applicant with a White-sounding name, controlling for other factors. The p-value 5e-05 indicates that there is a statistically significant difference in callback rates based on the name's racial association. Overall, the effect of having a Black-sounding name on a resume, as indicated by this analysis, suggests a statistically significant negative impact on the likelihood of being called back for an interview. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating Heterogeneous Effects"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8\n",
    "\n",
    "As you may recall from some past readings (such as this one on the [migraine medication Aimovig](https://ds4humans.com/30_questions/15_answering_exploratory_questions.html#faithful-representations)), our focus on estimating *Average Treatment Effects* runs the risk of papering over variation in how individuals respond. In the case of Aimovig, for example, nearly no patients actually experienced the Average Treatment Effect of the medication; around half of patients experienced no benefit, while the other half experienced a benefit of about twice the average treatment effect.\n",
    "\n",
    "So far in this analysis we've been focusing on the *average* effect of having a Black-sounding name (as compared to a White-sounding name). But we can actually use our regression framework to look for evidence of *heterogeneous treatment effects*—effects that are different for different types of people in our data. We accomplish this by *interacting* a variable we think may be related to experiencing a differential treatment effect with our treatment variable. For example, if we think that applicants with Black-sounding names who have a college degree are likely to experience less discrimination, we can interact `black` with an indicator for having a college degree. If having a college degree reduces discrimination, we could expect the interaction term to be positive. \n",
    "\n",
    "Is there more or less racial discrimination (the absolute magnitude difference in call back rates between Black and White applicants) among applicants who have a college degree? Store your answer as the string `\"more discrimination\"` or `\"less discrimination\"` under the key `\"ex8_college_heterogeneity\"`.\n",
    "\n",
    "Please still include `education`, `yearsexp`, `female`, and `computerskills` as controls.\n",
    "\n",
    "**Note:** it's relatively safe to assume that someone hiring employees who sees a resume that does *not* report education levels will assume the applicant does not have a college degree. So treat \"No education reported\" as \"not having a college degree.\"\n",
    "\n",
    "In percentage points, what is the difference in call back rates:\n",
    "\n",
    "- between White applicants without a college degree and Black applicants without a college degree (`ex8_black_nocollege`).\n",
    "- between White applicants with a college degree and Black applicants with a college degree (`ex8_black_college`).\n",
    "\n",
    "Use negative values to denote a lower probability for Black applicants to get a call back. **Scale so a value of `1` is a one percentage point difference. Please round your answer to 2 percentage points.**\n",
    "\n",
    "Focus on the coefficient values, even if the significance is low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>call</td>       <th>  R-squared:         </th> <td>   0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   5.064</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 04 Mar 2024</td> <th>  Prob (F-statistic):</th> <td>9.67e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:32:35</td>     <th>  Log-Likelihood:    </th> <td> -550.76</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4870</td>      <th>  AIC:               </th> <td>   1118.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4862</td>      <th>  BIC:               </th> <td>   1169.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     7</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>         <td>HC3</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>           <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>      <td>    0.0883</td> <td>    0.030</td> <td>    2.906</td> <td> 0.004</td> <td>    0.029</td> <td>    0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>black</th>          <td>   -0.0405</td> <td>    0.015</td> <td>   -2.735</td> <td> 0.006</td> <td>   -0.070</td> <td>   -0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>college</th>        <td>   -0.0071</td> <td>    0.021</td> <td>   -0.346</td> <td> 0.729</td> <td>   -0.047</td> <td>    0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>black:college</th>  <td>    0.0124</td> <td>    0.017</td> <td>    0.711</td> <td> 0.477</td> <td>   -0.022</td> <td>    0.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>education</th>      <td>   -0.0014</td> <td>    0.010</td> <td>   -0.133</td> <td> 0.894</td> <td>   -0.022</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yearsexp</th>       <td>    0.0032</td> <td>    0.001</td> <td>    3.670</td> <td> 0.000</td> <td>    0.001</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>female</th>         <td>    0.0112</td> <td>    0.010</td> <td>    1.157</td> <td> 0.247</td> <td>   -0.008</td> <td>    0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>computerskills</th> <td>   -0.0187</td> <td>    0.011</td> <td>   -1.648</td> <td> 0.099</td> <td>   -0.041</td> <td>    0.004</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>2950.174</td> <th>  Durbin-Watson:     </th> <td>   1.448</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>18623.672</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 3.046</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>10.393</td>  <th>  Cond. No.          </th> <td>    87.2</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors are heteroscedasticity robust (HC3)"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &       call       & \\textbf{  R-squared:         } &     0.008   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.007   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     5.064   \\\\\n",
       "\\textbf{Date:}             & Mon, 04 Mar 2024 & \\textbf{  Prob (F-statistic):} &  9.67e-06   \\\\\n",
       "\\textbf{Time:}             &     21:32:35     & \\textbf{  Log-Likelihood:    } &   -550.76   \\\\\n",
       "\\textbf{No. Observations:} &        4870      & \\textbf{  AIC:               } &     1118.   \\\\\n",
       "\\textbf{Df Residuals:}     &        4862      & \\textbf{  BIC:               } &     1169.   \\\\\n",
       "\\textbf{Df Model:}         &           7      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &       HC3        & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                        & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}      &       0.0883  &        0.030     &     2.906  &         0.004        &        0.029    &        0.148     \\\\\n",
       "\\textbf{black}          &      -0.0405  &        0.015     &    -2.735  &         0.006        &       -0.070    &       -0.011     \\\\\n",
       "\\textbf{college}        &      -0.0071  &        0.021     &    -0.346  &         0.729        &       -0.047    &        0.033     \\\\\n",
       "\\textbf{black:college}  &       0.0124  &        0.017     &     0.711  &         0.477        &       -0.022    &        0.046     \\\\\n",
       "\\textbf{education}      &      -0.0014  &        0.010     &    -0.133  &         0.894        &       -0.022    &        0.019     \\\\\n",
       "\\textbf{yearsexp}       &       0.0032  &        0.001     &     3.670  &         0.000        &        0.001    &        0.005     \\\\\n",
       "\\textbf{female}         &       0.0112  &        0.010     &     1.157  &         0.247        &       -0.008    &        0.030     \\\\\n",
       "\\textbf{computerskills} &      -0.0187  &        0.011     &    -1.648  &         0.099        &       -0.041    &        0.004     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 2950.174 & \\textbf{  Durbin-Watson:     } &     1.448  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000  & \\textbf{  Jarque-Bera (JB):  } & 18623.672  \\\\\n",
       "\\textbf{Skew:}          &   3.046  & \\textbf{  Prob(JB):          } &      0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  10.393  & \\textbf{  Cond. No.          } &      87.2  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors are heteroscedasticity robust (HC3)"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   call   R-squared:                       0.008\n",
       "Model:                            OLS   Adj. R-squared:                  0.007\n",
       "Method:                 Least Squares   F-statistic:                     5.064\n",
       "Date:                Mon, 04 Mar 2024   Prob (F-statistic):           9.67e-06\n",
       "Time:                        21:32:35   Log-Likelihood:                -550.76\n",
       "No. Observations:                4870   AIC:                             1118.\n",
       "Df Residuals:                    4862   BIC:                             1169.\n",
       "Df Model:                           7                                         \n",
       "Covariance Type:                  HC3                                         \n",
       "==================================================================================\n",
       "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------\n",
       "Intercept          0.0883      0.030      2.906      0.004       0.029       0.148\n",
       "black             -0.0405      0.015     -2.735      0.006      -0.070      -0.011\n",
       "college           -0.0071      0.021     -0.346      0.729      -0.047       0.033\n",
       "black:college      0.0124      0.017      0.711      0.477      -0.022       0.046\n",
       "education         -0.0014      0.010     -0.133      0.894      -0.022       0.019\n",
       "yearsexp           0.0032      0.001      3.670      0.000       0.001       0.005\n",
       "female             0.0112      0.010      1.157      0.247      -0.008       0.030\n",
       "computerskills    -0.0187      0.011     -1.648      0.099      -0.041       0.004\n",
       "==============================================================================\n",
       "Omnibus:                     2950.174   Durbin-Watson:                   1.448\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            18623.672\n",
       "Skew:                           3.046   Prob(JB):                         0.00\n",
       "Kurtosis:                      10.393   Cond. No.                         87.2\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors are heteroscedasticity robust (HC3)\n",
       "\"\"\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a new variable 'college' indicating whether the applicant has a college degree (1) or not (0)\n",
    "resume[\"college\"] = resume[\"education\"].apply(lambda x: 1 if x == 4 else 0)\n",
    "\n",
    "# Interacting 'black' with 'college' and including other controls in the model\n",
    "model_college_black = smf.ols(\n",
    "    formula=\"call ~ black * college + education + yearsexp + female + computerskills\",\n",
    "    data=resume,\n",
    ").fit(cov_type=\"HC3\")\n",
    "\n",
    "model_college_black.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient for the difference in likelihood of getting callback for Black applicants comparing to White applicants, controlling for other factors: -0.04053\n",
      "Coefficient for the difference in likelihood of getting callback for White applicants with college degree comparing to White applicants without college degree, controlling for other factors: -0.0071\n",
      "Coefficient for the difference in likelihood of getting callback for Black applicants with college degree comparing to Black applicants without college degree VS White applicants with college degree comparing to White applicants without college degree, controlling for other factors: 0.01237\n"
     ]
    }
   ],
   "source": [
    "# Getting the coefficients for the interaction term and the main effect\n",
    "coeff_black = model_college_black.params[1]\n",
    "coeff_college = model_college_black.params[2]\n",
    "coeff_interaction_black_college = model_college_black.params[3]\n",
    "\n",
    "print(\n",
    "    f\"Coefficient for the difference in likelihood of getting callback for Black applicants comparing to White applicants, controlling for other factors: {round (coeff_black, 5)}\"\n",
    ")\n",
    "print(\n",
    "    f\"Coefficient for the difference in likelihood of getting callback for White applicants with college degree comparing to White applicants without college degree, controlling for other factors: {round (coeff_college, 5)}\"\n",
    ")\n",
    "print(\n",
    "    f\"Coefficient for the difference in likelihood of getting callback for Black applicants with college degree comparing to Black applicants without college degree VS White applicants with college degree comparing to White applicants without college degree, controlling for other factors: {round (coeff_interaction_black_college, 5)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black applicants without a college degree is 4.05 percentage points less likely than White applicants without a college degree to get callback.\n",
      "Black applicants with a college degree is 2.82 percentage points less likely than White applicants with a college degree to get callback.\n",
      "There is less discrimination among applicants who have a college degree.\n"
     ]
    }
   ],
   "source": [
    "# Difference in callback rates without a college degree (just the effect of being black)\n",
    "ex8_black_nocollege = round((coeff_black * 100), 2)  # Scaling to percentage points\n",
    "\n",
    "# Difference in callback rates with a college degree (effect of being black + interaction term)\n",
    "ex8_black_college = round(\n",
    "    (coeff_black + coeff_interaction_black_college) * 100, 2\n",
    ")  # Scaling to percentage points\n",
    "\n",
    "# Interpretation of discrimination based on the interaction term\n",
    "ex8_college_heterogeneity = (\n",
    "    \"less discrimination\"\n",
    "    if coeff_interaction_black_college > 0\n",
    "    else \"more discrimination\"\n",
    ")\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"Black applicants without a college degree is {abs(ex8_black_nocollege)} percentage points less likely than White applicants without a college degree to get callback.\"\n",
    ")\n",
    "print(\n",
    "    f\"Black applicants with a college degree is {abs(ex8_black_college)} percentage points less likely than White applicants with a college degree to get callback.\"\n",
    ")\n",
    "print(\n",
    "    f\"There is {ex8_college_heterogeneity} among applicants who have a college degree.\"\n",
    ")\n",
    "\n",
    "results[\"ex8_black_nocollege\"] = ex8_black_nocollege\n",
    "results[\"ex8_black_college\"] = ex8_black_college\n",
    "results[\"ex8_college_heterogeneity\"] = ex8_college_heterogeneity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9\n",
    "\n",
    "Now let's compare men and women—is the penalty for having a Black-sounding name greater for Black men or Black women? Store your answer as `\"greater discrimination for men\"` or `\"greater discrimination for women\"` in `\"ex9_gender_and_discrimination\"`.\n",
    "\n",
    "Focus on the coefficient values, even if the significance is low.\n",
    "\n",
    "Again, please still include `education`, `yearsexp`, `female`, and `computerskills` as controls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>call</td>       <th>  R-squared:         </th> <td>   0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   3.866</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 04 Mar 2024</td> <th>  Prob (F-statistic):</th> <td>6.76e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:32:35</td>     <th>  Log-Likelihood:    </th> <td> -551.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4870</td>      <th>  AIC:               </th> <td>   1122.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4860</td>      <th>  BIC:               </th> <td>   1187.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     9</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>         <td>HC3</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>             <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>         <td>    0.0807</td> <td>    0.040</td> <td>    1.996</td> <td> 0.046</td> <td>    0.001</td> <td>    0.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(education)[T.1]</th> <td>   -0.0021</td> <td>    0.057</td> <td>   -0.037</td> <td> 0.971</td> <td>   -0.114</td> <td>    0.110</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(education)[T.2]</th> <td>   -0.0001</td> <td>    0.042</td> <td>   -0.003</td> <td> 0.998</td> <td>   -0.082</td> <td>    0.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(education)[T.3]</th> <td>   -0.0026</td> <td>    0.039</td> <td>   -0.066</td> <td> 0.947</td> <td>   -0.079</td> <td>    0.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(education)[T.4]</th> <td>   -0.0048</td> <td>    0.038</td> <td>   -0.125</td> <td> 0.900</td> <td>   -0.080</td> <td>    0.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>black</th>             <td>   -0.0287</td> <td>    0.016</td> <td>   -1.840</td> <td> 0.066</td> <td>   -0.059</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>female</th>            <td>    0.0131</td> <td>    0.014</td> <td>    0.919</td> <td> 0.358</td> <td>   -0.015</td> <td>    0.041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>black:female</th>      <td>   -0.0038</td> <td>    0.018</td> <td>   -0.213</td> <td> 0.831</td> <td>   -0.039</td> <td>    0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yearsexp</th>          <td>    0.0032</td> <td>    0.001</td> <td>    3.668</td> <td> 0.000</td> <td>    0.001</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>computerskills</th>    <td>   -0.0186</td> <td>    0.011</td> <td>   -1.618</td> <td> 0.106</td> <td>   -0.041</td> <td>    0.004</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>2950.616</td> <th>  Durbin-Watson:     </th> <td>   1.448</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>18630.964</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 3.047</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>10.395</td>  <th>  Cond. No.          </th> <td>    226.</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors are heteroscedasticity robust (HC3)"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &       call       & \\textbf{  R-squared:         } &     0.008   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.006   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     3.866   \\\\\n",
       "\\textbf{Date:}             & Mon, 04 Mar 2024 & \\textbf{  Prob (F-statistic):} &  6.76e-05   \\\\\n",
       "\\textbf{Time:}             &     21:32:35     & \\textbf{  Log-Likelihood:    } &   -551.00   \\\\\n",
       "\\textbf{No. Observations:} &        4870      & \\textbf{  AIC:               } &     1122.   \\\\\n",
       "\\textbf{Df Residuals:}     &        4860      & \\textbf{  BIC:               } &     1187.   \\\\\n",
       "\\textbf{Df Model:}         &           9      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &       HC3        & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                           & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}         &       0.0807  &        0.040     &     1.996  &         0.046        &        0.001    &        0.160     \\\\\n",
       "\\textbf{C(education)[T.1]} &      -0.0021  &        0.057     &    -0.037  &         0.971        &       -0.114    &        0.110     \\\\\n",
       "\\textbf{C(education)[T.2]} &      -0.0001  &        0.042     &    -0.003  &         0.998        &       -0.082    &        0.082     \\\\\n",
       "\\textbf{C(education)[T.3]} &      -0.0026  &        0.039     &    -0.066  &         0.947        &       -0.079    &        0.074     \\\\\n",
       "\\textbf{C(education)[T.4]} &      -0.0048  &        0.038     &    -0.125  &         0.900        &       -0.080    &        0.070     \\\\\n",
       "\\textbf{black}             &      -0.0287  &        0.016     &    -1.840  &         0.066        &       -0.059    &        0.002     \\\\\n",
       "\\textbf{female}            &       0.0131  &        0.014     &     0.919  &         0.358        &       -0.015    &        0.041     \\\\\n",
       "\\textbf{black:female}      &      -0.0038  &        0.018     &    -0.213  &         0.831        &       -0.039    &        0.031     \\\\\n",
       "\\textbf{yearsexp}          &       0.0032  &        0.001     &     3.668  &         0.000        &        0.001    &        0.005     \\\\\n",
       "\\textbf{computerskills}    &      -0.0186  &        0.011     &    -1.618  &         0.106        &       -0.041    &        0.004     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 2950.616 & \\textbf{  Durbin-Watson:     } &     1.448  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000  & \\textbf{  Jarque-Bera (JB):  } & 18630.964  \\\\\n",
       "\\textbf{Skew:}          &   3.047  & \\textbf{  Prob(JB):          } &      0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  10.395  & \\textbf{  Cond. No.          } &      226.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors are heteroscedasticity robust (HC3)"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   call   R-squared:                       0.008\n",
       "Model:                            OLS   Adj. R-squared:                  0.006\n",
       "Method:                 Least Squares   F-statistic:                     3.866\n",
       "Date:                Mon, 04 Mar 2024   Prob (F-statistic):           6.76e-05\n",
       "Time:                        21:32:35   Log-Likelihood:                -551.00\n",
       "No. Observations:                4870   AIC:                             1122.\n",
       "Df Residuals:                    4860   BIC:                             1187.\n",
       "Df Model:                           9                                         \n",
       "Covariance Type:                  HC3                                         \n",
       "=====================================================================================\n",
       "                        coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------\n",
       "Intercept             0.0807      0.040      1.996      0.046       0.001       0.160\n",
       "C(education)[T.1]    -0.0021      0.057     -0.037      0.971      -0.114       0.110\n",
       "C(education)[T.2]    -0.0001      0.042     -0.003      0.998      -0.082       0.082\n",
       "C(education)[T.3]    -0.0026      0.039     -0.066      0.947      -0.079       0.074\n",
       "C(education)[T.4]    -0.0048      0.038     -0.125      0.900      -0.080       0.070\n",
       "black                -0.0287      0.016     -1.840      0.066      -0.059       0.002\n",
       "female                0.0131      0.014      0.919      0.358      -0.015       0.041\n",
       "black:female         -0.0038      0.018     -0.213      0.831      -0.039       0.031\n",
       "yearsexp              0.0032      0.001      3.668      0.000       0.001       0.005\n",
       "computerskills       -0.0186      0.011     -1.618      0.106      -0.041       0.004\n",
       "==============================================================================\n",
       "Omnibus:                     2950.616   Durbin-Watson:                   1.448\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            18630.964\n",
       "Skew:                           3.047   Prob(JB):                         0.00\n",
       "Kurtosis:                      10.395   Cond. No.                         226.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors are heteroscedasticity robust (HC3)\n",
       "\"\"\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we want to use female as an interaction term here because we are concerned with black men and black females\n",
    "model_gender_black = smf.ols(\n",
    "    formula=\"call ~ black*female + yearsexp + computerskills + C(education)\",\n",
    "    data=resume,\n",
    ").fit(cov_type=\"HC3\")\n",
    "\n",
    "model_gender_black.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient for the difference in likelihood of getting callback for Black applicants comparing to White applicants, controlling for other factors: -0.02866\n",
      "Coefficient for the difference in likelihood of getting callback for female White applicants comparing to male White applicants, controlling for other factors: 0.01313\n",
      "Coefficient for the difference in likelihood of getting callback for female Black applicants comparing to male Black applicants VS female White applicants comparing to male White applicants, controlling for other factors: -0.00384\n"
     ]
    }
   ],
   "source": [
    "# Getting the coefficients for the interaction term and the main effect\n",
    "coeff_black_new = model_gender_black.params[5]\n",
    "coeff_female = model_gender_black.params[6]\n",
    "coeff_interaction_black_female = model_gender_black.params[7]\n",
    "\n",
    "print(\n",
    "    f\"Coefficient for the difference in likelihood of getting callback for Black applicants comparing to White applicants, controlling for other factors: {round (coeff_black_new, 5)}\"\n",
    ")\n",
    "print(\n",
    "    f\"Coefficient for the difference in likelihood of getting callback for female White applicants comparing to male White applicants, controlling for other factors: {round (coeff_female, 5)}\"\n",
    ")\n",
    "print(\n",
    "    f\"Coefficient for the difference in likelihood of getting callback for female Black applicants comparing to male Black applicants VS female White applicants comparing to male White applicants, controlling for other factors: {round (coeff_interaction_black_female, 5)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The penalty for having a Black-sounding name greater for Black women.\n"
     ]
    }
   ],
   "source": [
    "# Interpretation of discrimination\n",
    "ex9_gender_and_discrimination = (\n",
    "    \"greater discrimination for men\"\n",
    "    if coeff_interaction_black_female > 0\n",
    "    else \"greater discrimination for women\"\n",
    ")\n",
    "\n",
    "if ex9_gender_and_discrimination == \"greater discrimination for men\":\n",
    "    print(\"The penalty for having a Black-sounding name greater for Black men.\")\n",
    "else:\n",
    "    print(\"The penalty for having a Black-sounding name greater for Black women.\")\n",
    "\n",
    "results[\"ex9_gender_and_discrimination\"] = ex9_gender_and_discrimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The interaction term of -0.38 percentage points suggests that the penalty for being a Black woman is slightly more pronounced than for Black men when compared to their White counterparts.\n",
      "Therefore, the penalty for having a Black-sounding name greater for Black women.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"The interaction term of {round(coeff_interaction_black_female*100,2)} percentage points suggests that the penalty for being a Black woman is slightly more pronounced than for Black men when compared to their White counterparts.\"\n",
    ")\n",
    "print(\n",
    "    \"Therefore, the penalty for having a Black-sounding name greater for Black women.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 10\n",
    "\n",
    "Calculate and/or lookup the following online:\n",
    "\n",
    "- What is the share of applicants in our dataset with college degrees?\n",
    "- What share of Black adult Americans have college degrees (i.e. have completed a bachelors degree)?\n",
    "\n",
    "Is the share of Black applicants with college degrees in this data `\"greater\"`, or `\"less\"` than in the US? Store your answer as one of those strings in `\"ex10_experiment_v_us\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Share of applicants in the dataset with college degrees in this dataset: 71.95%\n",
      "Share of Black adult Americans with college degrees in this dataset: 72.28%\n"
     ]
    }
   ],
   "source": [
    "# Calculate the share of applicants in the dataset with college degrees\n",
    "share_college_degrees = (resume[\"education\"] == 4).mean()\n",
    "\n",
    "# Calculate the share of Black adult Americans with college degrees (i.e. have completed a bachelors degree)\n",
    "share_black_college_degrees = (\n",
    "    resume.groupby(\"black\")[\"education\"].apply(lambda x: (x == 4).mean()).loc[1]\n",
    ")\n",
    "\n",
    "# Print the results\n",
    "print(\n",
    "    f\"Share of applicants in the dataset with college degrees in this dataset: {share_college_degrees:.2%}\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Share of Black adult Americans with college degrees in this dataset: {share_black_college_degrees:.2%}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> According to the [Census' American Community Survey](https://www.census.gov/programs-surveys/acs), in 2021 12% of the total U.S. population identified as Black or African American. Among Black residents aged 25 or over, 22.6% had earned a bachelor's degree or higher. This rate is up from 17.9% in 2010, but falls short of the national rate of 32.9%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The share of Black applicants with college degrees in this data is greater than in the US.\n"
     ]
    }
   ],
   "source": [
    "national_share_black_college_degrees = 0.226\n",
    "# Compare the two shares\n",
    "if share_black_college_degrees > 0.226:\n",
    "    ex10_experiment_v_us = \"greater\"\n",
    "else:\n",
    "    ex10_experiment_v_us = \"less\"\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"The share of Black applicants with college degrees in this data is {ex10_experiment_v_us} than in the US.\"\n",
    ")\n",
    "\n",
    "results[\"ex10_experiment_v_us\"] = ex10_experiment_v_us"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11\n",
    "\n",
    "Bearing in mind your answers to Exercise 8 and to Exercise 10, how do you think the Average Treatment Effect you estimated in Exercises 5 and 6 might generalize to the experience of the average Black American (i.e., how do you think the ATE for the average Black American would compare to the ATE estimated from this experiment)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - The analysis revealed a statistically significant negative impact of having a Black-sounding name on callback rates for interviews, quantified as a 3.2 percentage points lower likelihood compared to having a White-sounding name. The experiment showed that discrimination based on name varies by educational attainment. Although Black applicants, both with and without college degrees, face discrimination, the penalty is less severe for those with a college degree.\n",
    "> - However, the share of Black applicants with college degrees in the dataset is significantly higher than the national average for Black Americans (71.95% in the dataset vs. 22.6% nationally). This discrepancy indicates that the sample may not be fully representative of the broader Black American population in terms of educational attainment.\n",
    "> - The higher educational attainment among the sample suggests that the ATE derived from this dataset may not fully capture the experiences of the broader Black population, particularly those without college degrees, who might face more severe discrimination. Therefore, the Average Treatment Effect I estimated in Exercises 5 and 6 might not generalize to the experience of the average Black American. The ATE for the average Black American in the U.S. may be more severe compare to the ATE estimated from this experiment, given the share of Black applicants with college degrees in the dataset is significantly higher than the national average for Black Americans."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12\n",
    "\n",
    "What does your answer to Exercise 10 imply about the study's *internal* validity?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> My answer to Exercise 10 doesn't imply anything about the study's internal validity. The internal validity of the study holds since the study's design and execution in establishing causal relationships is valid."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 13\n",
    "\n",
    "What does your answer to Exercise 10 imply about the study's *external* validity?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> My answer to Exercise 10 implies the study's external validity is poor since the broader applicability of the findings is poor. The higher educational attainment among the sample suggests that the ATE derived from this dataset may not fully capture the experiences of the broader Black population, particularly those without college degrees, who might face more severe discrimination. Therefore, the Average Treatment Effect I estimated in Exercises 5 and 6 might not generalize to the experience of the average Black American. The ATE for the average Black American in the U.S. may be more severe compare to the ATE estimated from this experiment, given the share of Black applicants with college degrees in the dataset is significantly higher than the national average for Black Americans. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Did We Just Measure?\n",
    "\n",
    "It's worth pausing for a moment to think about exactly what we've measured in this experiment. Was it the effect of race on hiring? Or the difference in the experience of the average White job applicant from the average Black job applicant?\n",
    "\n",
    "Well... no. What we have measured in this experiment is **just** the effect of having a Black-sounding name (as opposed to a White-sounding name) on your resume on the likelihood of getting a followup call from someone hiring in Boston or Chicago given identical resumes. In that sense, what we've measured is a small *piece* of the difference in the experience of Black and White Americans when seeking employment. As anyone looking for a job knows, getting a call-back is obviously a crucial step in getting a job, so this difference—even if it's just one part of the overall difference—is remarkable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ex2_pvalue_female': 0.38,\n",
       " 'ex2_pvalue_computerskills': 0.03,\n",
       " 'ex2_pvalue_yearsexp': 0.85,\n",
       " 'ex3_pvalue_education': 0.49,\n",
       " 'ex4_validity': 'internal',\n",
       " 'ex5_white_advantage_percent': 49.68,\n",
       " 'ex5_white_advantage_percentage_points': 3.2,\n",
       " 'ex5_pvalue': 4e-05,\n",
       " 'ex6_black_pvalue': 4e-05,\n",
       " 'ex8_black_nocollege': -4.05,\n",
       " 'ex8_black_college': -2.82,\n",
       " 'ex8_college_heterogeneity': 'less discrimination',\n",
       " 'ex9_gender_and_discrimination': 'greater discrimination for women',\n",
       " 'ex10_experiment_v_us': 'greater'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(results.keys()) == {\n",
    "    \"ex2_pvalue_computerskills\",\n",
    "    \"ex2_pvalue_female\",\n",
    "    \"ex2_pvalue_yearsexp\",\n",
    "    \"ex3_pvalue_education\",\n",
    "    \"ex4_validity\",\n",
    "    \"ex5_pvalue\",\n",
    "    \"ex5_white_advantage_percent\",\n",
    "    \"ex5_white_advantage_percentage_points\",\n",
    "    \"ex6_black_pvalue\",\n",
    "    \"ex8_black_college\",\n",
    "    \"ex8_black_nocollege\",\n",
    "    \"ex8_college_heterogeneity\",\n",
    "    \"ex9_gender_and_discrimination\",\n",
    "    \"ex10_experiment_v_us\",\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "718fed28bf9f8c7851519acf2fb923cd655120b36de3b67253eeb0428bd33d2d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
